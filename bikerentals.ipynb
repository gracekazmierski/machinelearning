{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIKESSS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gracekazmierski/machinelearning/blob/main/bikerentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Major COVID-19 Restriction and Lockdown Periods in Beijing\n",
        "\n",
        "###Early COVID-19 Pandemic (Early 2020)\n",
        "####Start:\n",
        "On January 23, 2020, as Wuhan went into lockdown, strict travel restrictions and prevention measures began across China. Beijing also implemented inter-city travel controls, closed public facilities, and recommended working from home.\n",
        "####End:\n",
        "In early April 2020, with the official lifting of Wuhan's lockdown, high-intensity national restrictions gradually eased. Beijing also began to normalize around this time.\n",
        "\n",
        "###Spring 2022 (Omicron Variant Spread)\n",
        "####Start:\n",
        "In late April 2022, as Omicron variant cases surged in Beijing, severe restrictions resumed. April 25, 2022, marked the start of large-scale nucleic acid testing, accompanied by widespread measures such as residential compound lockdowns, bans on dine-in services, school closures, and the suspension of some subway stations.\n",
        "\n",
        "####End:\n",
        "In early June 2022, as the number of cases declined, Beijing authorities began lifting most lockdown measures and promoting normalization starting June 6, 2022. However, partial lockdowns of specific areas continued if sporadic cases emerged.\n",
        "\n",
        "###Autumn 2022 (Just Before Zero-COVID Policy Repeal)\n",
        "####Start:\n",
        "From late October through November 2022, the number of cases surged in Beijing and other major Chinese cities, reaching the peak of the 'Zero-COVID' policy's intensity. Specific districts in Beijing, like Chaoyang District, experienced controls akin to full lockdowns. While the exact start date varied by region, these controls significantly intensified around mid-November 2022.\n",
        "####End:\n",
        "The Chinese government officially announced the repeal of the nationwide 'Zero-COVID' policy on December 7, 2022, effectively ending Beijing's severe restrictions. Although the number of cases surged thereafter, policy-wise, mandatory lockdowns and mass testing were eliminated."
      ],
      "metadata": {
        "id": "zgK1aLU4nNq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load the Data ---\n",
        "try:\n",
        "    df = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "    print(\"bikes.csv file has been loaded.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"The file could not be found.\")\n",
        "    exit()\n",
        "\n",
        "# 'dteday' to datetime\n",
        "df['dteday'] = pd.to_datetime(df['dteday'])\n",
        "\n",
        "# Create total_rentals column (casual + registered)\n",
        "df['total_rentals'] = df['casual'] + df['registered']\n",
        "\n",
        "# --- Feature Engineering  ---\n",
        "\n",
        "# 1. Features about Time\n",
        "df['year'] = df['dteday'].dt.year\n",
        "df['month'] = df['dteday'].dt.month\n",
        "df['day_of_week'] = df['dteday'].dt.dayofweek # Monday=0, Sunday=6\n",
        "\n",
        "# 2. Create avg_temp_c column (temp_c + feels_like_c)\n",
        "df['avg_temp_c'] = (df['temp_c'] + df['feels_like_c']) / 2\n",
        "\n",
        "# 3. COVID-19 period\n",
        "\n",
        "# 3-1. First covid\n",
        "df['is_early_covid_2020'] = 0\n",
        "df.loc[(df['dteday'] >= pd.to_datetime('2020-01-23')) &\n",
        "       (df['dteday'] <= pd.to_datetime('2020-04-05')), 'is_early_covid_2020'] = 1\n",
        "\n",
        "# 3-2. Omicron(Lockdown and ban public transportation)\n",
        "df['is_spring_2022_omicron'] = 0\n",
        "df.loc[(df['dteday'] >= pd.to_datetime('2022-04-25')) &\n",
        "       (df['dteday'] <= pd.to_datetime('2022-06-05')), 'is_spring_2022_omicron'] = 1\n",
        "\n",
        "# 3-3. Zero-covid in Beijing (Lockdown and ban public transportation)\n",
        "df['is_autumn_2022_zero_covid'] = 0\n",
        "df.loc[(df['dteday'] >= pd.to_datetime('2022-10-20')) &\n",
        "       (df['dteday'] <= pd.to_datetime('2022-12-06')), 'is_autumn_2022_zero_covid'] = 1\n",
        "\n",
        "# 4. Commute time (AM 7-9, PM 4-6)\n",
        "df['is_commute_hour'] = 0\n",
        "df.loc[((df['hr'] >= 7) & (df['hr'] <= 9)) |\n",
        "       ((df['hr'] >= 16) & (df['hr'] <= 18)), 'is_commute_hour'] = 1\n",
        "\n",
        "# 5. Weather + Hr\n",
        "df['weathersit_hr_interaction'] = df['weathersit'].astype(str) + '_' + df['hr'].astype(str)\n",
        "\n",
        "\n",
        "# Target\n",
        "features = ['season', 'hr', 'holiday', 'workingday', 'weathersit',\n",
        "            'avg_temp_c', 'hum', 'windspeed',\n",
        "            'year', 'month', 'day_of_week',\n",
        "            'is_early_covid_2020', 'is_spring_2022_omicron', 'is_autumn_2022_zero_covid',\n",
        "            'is_commute_hour',\n",
        "            'weathersit_hr_interaction']\n",
        "target = 'total_rentals'\n",
        "\n",
        "# categorical and numerical features setting\n",
        "categorical_features = ['season', 'hr', 'holiday', 'workingday', 'weathersit',\n",
        "                        'month', 'day_of_week', 'year',\n",
        "                        'is_early_covid_2020', 'is_spring_2022_omicron', 'is_autumn_2022_zero_covid',\n",
        "                        'is_commute_hour',\n",
        "                        'weathersit_hr_interaction']\n",
        "numerical_features = ['avg_temp_c', 'hum', 'windspeed']\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G-DY7GTvSP18",
        "outputId": "603da429-c7ca-457e-fb3f-e52dc8d373a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bikes.csv file has been loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepocessing Pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', MinMaxScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# --- Data split ---\n",
        "# Train set: 2011 to August 2023\n",
        "train_df = df[(df['dteday'].dt.year < 2023) |\n",
        "              ((df['dteday'].dt.year == 2023) & (df['dteday'].dt.month <= 8))]\n",
        "# Internal Verification/Test Set: September 2023 to October 2023\n",
        "test_df = df[(df['dteday'].dt.year == 2023) & (df['dteday'].dt.month > 8)]\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target]\n",
        "X_test = test_df[features] # Internal Verification/Test Set\n",
        "y_test = test_df[target]\n",
        "\n",
        "print(f\"\\nTain data Scale: {X_train.shape[0]}\")\n",
        "print(f\"Internal Verification/Test Set Scale (2023.09 - 2023.10): {X_test.shape[0]}\")\n",
        "\n",
        "# Preprocessor training and conversion (fit only with training data)\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "# Internal verification/test data is only transformed with trained preprocessor\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "print(f\"\\nTraining data shape after preprocessing: {X_train_processed.shape}\")\n",
        "print(f\"After preprocessing, internal verification/test data shape: {X_test_processed.shape}\")\n",
        "\n",
        "# Size of the input layer\n",
        "input_shape = X_train_processed.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB8FQODCYnHd",
        "outputId": "772ef414-4fd3-4c0f-a4b5-7c7c886edf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tain data Scale: 111011\n",
            "Internal Verification/Test Set Scale (2023.09 - 2023.10): 1464\n",
            "\n",
            "Training data shape after preprocessing: (111011, 175)\n",
            "After preprocessing, internal verification/test data shape: (1464, 175)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hyperparameter tuning with Early Stopping ---\n",
        "\n",
        "# Define the hyperparameter grid to explore\n",
        "learning_rates = [0.001, 0.0005]\n",
        "layer_configs = [\n",
        "    [128, 64, 32],      # Default\n",
        "    [256, 128, 64],     # Larger\n",
        "    [64, 32]          # Smaller\n",
        "]\n",
        "dropout_rates = [0.1, 0.3]\n",
        "\n",
        "best_mae = float('inf')\n",
        "best_params = {}\n",
        "best_model = None\n",
        "best_predictions_test = None\n",
        "best_y_test = None\n",
        "\n",
        "print(\"\\nStart tuning hyperparameters (Early Stopping applied)...\")\n",
        "tune_results = []\n",
        "\n",
        "# EarlyStopping Callback\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VJdl_QegYvkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in learning_rates:\n",
        "    for config in layer_configs:\n",
        "        for drop_rate in dropout_rates:\n",
        "            tf.keras.backend.clear_session() # Initialize sessions before training each model\n",
        "\n",
        "            # Build a model\n",
        "            model_tuned = keras.Sequential([\n",
        "                layers.Input(shape=(input_shape,))\n",
        "            ])\n",
        "            for neurons in config:\n",
        "                model_tuned.add(layers.Dense(neurons, activation='relu'))\n",
        "                model_tuned.add(layers.Dropout(drop_rate))\n",
        "            model_tuned.add(layers.Dense(1)) # Output layer\n",
        "\n",
        "            # Compilation of models\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "            model_tuned.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "            # Model training (Early Stopping applied)\n",
        "            history = model_tuned.fit(X_train_processed, y_train,\n",
        "                                      epochs=200, # Set a sufficiently large number of epochs (early stopping early)\n",
        "                                      batch_size=32,\n",
        "                                      validation_data=(X_test_processed, y_test), # Monitor val_loss with internal validation/test set\n",
        "                                      callbacks=[early_stopping_callback], # Add callback\n",
        "                                      verbose=1)\n",
        "\n",
        "            # Evaluation of the test dataset\n",
        "            loss, mae = model_tuned.evaluate(X_test_processed, y_test, verbose=0)\n",
        "            predictions_test = model_tuned.predict(X_test_processed).flatten()\n",
        "            predictions_test = np.maximum(0, predictions_test) # Negative # = 0\n",
        "\n",
        "            # Calculate additional indicators (R^2, Within %)\n",
        "            r2 = r2_score(y_test, predictions_test)\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, predictions_test))\n",
        "            median_abs_error = np.median(np.abs(y_test - predictions_test))\n",
        "\n",
        "            # Division by zero prevention for cases where y_test is 0\n",
        "            abs_errors_ratio = np.abs(y_test - predictions_test) / np.maximum(y_test, 1e-6)\n",
        "\n",
        "            within_5_percent = np.mean(abs_errors_ratio * 100 <= 5) * 100\n",
        "            within_10_percent = np.mean(abs_errors_ratio * 100 <= 10) * 100\n",
        "            within_20_percent = np.mean(abs_errors_ratio * 100 <= 20) * 100\n",
        "\n",
        "\n",
        "            print(f\"LR: {lr:.5f}, Layers: {config}, Dropout: {drop_rate:.1f} -> MAE: {mae:.2f}, R2: {r2:.4f}, Within 20%: {within_20_percent:.2f}%\")\n",
        "\n",
        "            tune_results.append({\n",
        "                'learning_rate': lr,\n",
        "                'layer_config': config,\n",
        "                'dropout_rate': drop_rate,\n",
        "                'mae': mae,\n",
        "                'rmse': rmse,\n",
        "                'r2': r2,\n",
        "                'within_5_percent': within_5_percent,\n",
        "                'within_10_percent': within_10_percent,\n",
        "                'within_20_percent': within_20_percent\n",
        "            })\n",
        "\n",
        "            # Best Model Update (based on MAE)\n",
        "            if mae < best_mae:\n",
        "                best_mae = mae\n",
        "                best_params = {'learning_rate': lr, 'layer_config': config, 'dropout_rate': drop_rate}\n",
        "                best_model = model_tuned\n",
        "                best_predictions_test = predictions_test\n",
        "                best_y_test = y_test # Save the actual y_test value\n",
        "\n",
        "print(\"\\nHyperparameter tuning completed.\")\n",
        "print(f\"\\nOptimal hyperparameters: {best_params}\")\n",
        "print(f\"Optimal MAE: {best_mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CJ0355BuY9De",
        "outputId": "7fcdc6b6-642a-4c3d-f1b9-c080eab4b1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m 867/3470\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 104598.1328 - mae: 216.0402"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f1147a892104>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Model training (Early Stopping applied)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             history = model_tuned.fit(X_train_processed, y_train,\n\u001b[0m\u001b[1;32m     21\u001b[0m                                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Set a sufficiently large number of epochs (early stopping early)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output final performance metrics for optimal models\n",
        "print(\"\\nInternal Validation/Test Dataset of Optimal Models (September, October 2023) Final Performance:\")\n",
        "final_r2 = r2_score(best_y_test, best_predictions_test)\n",
        "final_rmse = np.sqrt(mean_squared_error(best_y_test, best_predictions_test))\n",
        "final_mae = mean_absolute_error(best_y_test, best_predictions_test)\n",
        "final_median_abs_error = np.median(np.abs(best_y_test - best_predictions_test))\n",
        "\n",
        "# Division by zero prevention when y_test is 0 (also applied to final performance calculations)\n",
        "abs_errors_ratio_final = np.abs(best_y_test - best_predictions_test) / np.maximum(best_y_test, 1e-6)\n",
        "\n",
        "final_within_5_percent = np.mean(abs_errors_ratio_final * 100 <= 5) * 100\n",
        "final_within_10_percent = np.mean(abs_errors_ratio_final * 100 <= 10) * 100\n",
        "final_within_20_percent = np.mean(abs_errors_ratio_final * 100 <= 20) * 100\n",
        "\n",
        "print(f\"R^2: {final_r2:.4f}\")\n",
        "print(f\"RMSE: {final_rmse:.2f}\")\n",
        "print(f\"Mean Absolute Error: {final_mae:.2f}\")\n",
        "print(f\"Median Absolute Error: {final_median_abs_error:.2f}\")\n",
        "print(f\"Within 5%: {final_within_5_percent:.2f}%\")\n",
        "print(f\"Within 10%: {final_within_10_percent:.2f}%\")\n",
        "print(f\"Within 20%: {final_within_20_percent:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTL6_x3WZDXb",
        "outputId": "4e5a9207-e63a-45a5-9482-2ba1b0abae43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Internal Validation/Test Dataset of Optimal Models (September, October 2023) Final Performance:\n",
            "R^2: 0.9598\n",
            "RMSE: 100.41\n",
            "Mean Absolute Error: 68.03\n",
            "Median Absolute Error: 42.94\n",
            "Within 5%: 26.30%\n",
            "Within 10%: 50.55%\n",
            "Within 20%: 77.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save the optimal model ---\n",
        "model_save_path = 'best_bike_rental_model.keras'\n",
        "if best_model is not None:\n",
        "    best_model.save(model_save_path)\n",
        "    print(f\"\\nThe Best model has been saved to '{model_save_path}'.\")\n",
        "else:\n",
        "    print(\"\\nUnable to save because the optimal model was not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgKYe_uHYENV",
        "outputId": "c86c7b4e-7365-4c21-aa19-18982ed75311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The Best model has been saved to 'best_bike_rental_model.keras'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_load_path = 'best_bike_rental_model.keras'\n",
        "\n",
        "try:\n",
        "    # load the model\n",
        "    loaded_model = tf.keras.models.load_model(model_load_path)\n",
        "    print(f\"The model has been successfully laoded from '{model_load_path}'.\")\n",
        "\n",
        "    # Output summary information of the loaded model (make sure the model is loaded properly)\n",
        "    loaded_model.summary()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the model.: {e}\")\n",
        "    print(\"Please check the file path, or verify that the model is stored correctly in that path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "X0G6hgnegAQI",
        "outputId": "18fcea11-03e5-44ad-e16d-514937e35f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has been successfully laoded from 'best_bike_rental_model.keras'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m45,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">45,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m258,821\u001b[0m (1011.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,821</span> (1011.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,273\u001b[0m (337.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,273</span> (337.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m172,548\u001b[0m (674.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,548</span> (674.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predictions and file storage for holdout datasets (using optimal models) ---\n",
        "\n",
        "\n",
        "print(\"\\nLoad holdout dataset and start prediction...\")\n",
        "\n",
        "try:\n",
        "    # biking_holdout_test_mini.csv load\n",
        "    holdout_df = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv')\n",
        "    print(\"biking_holdout_test_mini.csv has been successfully loaded\")\n",
        "except FileNotFoundError:\n",
        "    print(\"biking_holdout_test_mini.csv could not be found.\")\n",
        "    exit()\n",
        "\n",
        "# Convert 'dteday' column to datetime format (also applies to holdout_df)\n",
        "holdout_df['dteday'] = pd.to_datetime(holdout_df['dteday'])\n",
        "\n",
        "# Add features to the holdout dataset (apply new features added to the df equally to holdout_df)\n",
        "holdout_df['year'] = holdout_df['dteday'].dt.year\n",
        "holdout_df['month'] = holdout_df['dteday'].dt.month\n",
        "holdout_df['day_of_week'] = holdout_df['dteday'].dt.dayofweek\n",
        "\n",
        "# Avg_temp_c\n",
        "holdout_df['avg_temp_c'] = (holdout_df['temp_c'] + holdout_df['feels_like_c']) / 2\n",
        "\n",
        "# 1. COVID-19\n",
        "holdout_df['is_early_covid_2020'] = 0\n",
        "holdout_df.loc[(holdout_df['dteday'] >= pd.to_datetime('2020-01-23')) &\n",
        "               (holdout_df['dteday'] <= pd.to_datetime('2020-04-05')), 'is_early_covid_2020'] = 1\n",
        "\n",
        "holdout_df['is_spring_2022_omicron'] = 0\n",
        "holdout_df.loc[(holdout_df['dteday'] >= pd.to_datetime('2022-04-25')) &\n",
        "               (holdout_df['dteday'] <= pd.to_datetime('2022-06-05')), 'is_spring_2022_omicron'] = 1\n",
        "\n",
        "holdout_df['is_autumn_2022_zero_covid'] = 0\n",
        "holdout_df.loc[(holdout_df['dteday'] >= pd.to_datetime('2022-10-20')) &\n",
        "               (holdout_df['dteday'] <= pd.to_datetime('2022-12-06')), 'is_autumn_2022_zero_covid'] = 1\n",
        "\n",
        "# 2. commute time\n",
        "holdout_df['is_commute_hour'] = 0\n",
        "holdout_df.loc[((holdout_df['hr'] >= 7) & (holdout_df['hr'] <= 9)) |\n",
        "               ((holdout_df['hr'] >= 16) & (holdout_df['hr'] <= 18)), 'is_commute_hour'] = 1\n",
        "\n",
        "# 3. weather + hr\n",
        "holdout_df['weathersit_hr_interaction'] = holdout_df['weathersit'].astype(str) + '_' + holdout_df['hr'].astype(str)\n",
        "\n",
        "# extract the features\n",
        "X_holdout = holdout_df[features]\n",
        "\n",
        "print(f\"\\nholdout dataset scale: {X_holdout.shape[0]}\")\n",
        "\n",
        "# Transform the preprocessed holdout dataset (using transform instead of fit_transform)\n",
        "X_holdout_processed = preprocessor.transform(X_holdout)\n",
        "\n",
        "print(f\"After preprocessing holdout dataset Shape: {X_holdout_processed.shape}\")\n",
        "\n",
        "# Performing predictions on the holdout dataset\n",
        "holdout_predictions = best_model.predict(X_holdout_processed).flatten()\n",
        "\n",
        "# Because the prediction may be negative, treat less than 0 as 0\n",
        "holdout_predictions = np.maximum(0, holdout_predictions)\n",
        "\n",
        "# Create DataFrame to contain predictive results and set column names to meet requirements\n",
        "predictions_output_df = pd.DataFrame(holdout_predictions, columns=['predictions'])\n",
        "\n",
        "# Set the file name (team4-module4-predictions.csv)\n",
        "output_filename_holdout = 'team4-module4-predictions.csv'\n",
        "\n",
        "# Save to csv file\n",
        "predictions_output_df.to_csv(output_filename_holdout, index=False)\n",
        "\n",
        "print(f\"\\nholdout dataset's predictions has been saved to '{output_filename_holdout}'.\")\n",
        "print(\"\\nPreview holdout prediction results (top five):\")\n",
        "print(predictions_output_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6x4FxGnYW-u",
        "outputId": "d913c2d4-bbac-4f10-c004-89a0929978e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Load holdout dataset and start prediction...\n",
            "biking_holdout_test_mini.csv has been successfully loaded\n",
            "\n",
            "holdout dataset scale: 384\n",
            "After preprocessing holdout dataset Shape: (384, 175)\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\n",
            "holdout dataset's predictions has been saved to 'team4-module4-predictions.csv'.\n",
            "\n",
            "Preview holdout prediction results (top five):\n",
            "   predictions\n",
            "0    72.510139\n",
            "1    38.069267\n",
            "2    16.789047\n",
            "3    10.851306\n",
            "4    15.733383\n"
          ]
        }
      ]
    }
  ]
}